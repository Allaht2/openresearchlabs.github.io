<!DOCTYPE html>
<html>  
  
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TKO_3121: Topics</title>
  <meta name="description" content="Research homepage. University of Turku, Finland. PI Leo Lahti. >">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="/edu/tko3121/">
<link rel="shortcut icon" type ="image/x-icon" href="/images/favicon.ico">



</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
    <a class="navbar-brand" href="/">Turku Data Science Group</a>
	</div>
	
	<div class="collapse navbar-collapse" id="navbar-collapse-1">

	  <ul class="nav navbar-nav navbar-right">
		<li><a href="/">Home</a></li>
		<li><a href="/allnews">News</a></li>
		<li><a href="/team">Team</a></li>
		<li><a href="/research">Research</a></li>		
		<li><a href="/publications">Publications</a></li>
		<li><a href="/code">Code</a></li>
		<li><a href="/media">Media</a></li>
		<li><a href="/edu">Teaching</a></li>	
		<li><a href="/contact">Contact</a></li>		
	  </ul>
	  
	</div>
  </div>

</div>


    <p></p>
    
    <div class="container-fluid">
      <div class="row">

	<p style="margin-bottom:50px;"></p>
	
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">TKO_3121: Topics</h1>
  </header>

  <article class="post-content">
    <h1 id="machine-learning-and-algorithmics-seminar-2020">Machine Learning and Algorithmics Seminar 2020</h1>

<ul>
  <li><a href="https://opas.peppi.utu.fi/fi/opintojakso/TKO_3121/3255">Course page (Peppi)</a></li>
  <li><a href="https://moodle.utu.fi/course/view.php?id=17982">Moodle for Machine Learning and Algorithmics Seminar 2020</a></li>
</ul>

<h2 id="proposed-seminar-topics">Proposed seminar topics</h2>

<h3 id="session-1-introduction">Session 1: Introduction</h3>

<ul>
  <li>Participants</li>
  <li>Overview and practicalities</li>
  <li>Assigning the topics</li>
</ul>

<h3 id="session-2-overview">Session 2: Overview</h3>

<ul>
  <li>Introduction lecture: contemporary themes in machine learning</li>
  <li>Discussion</li>
  <li>Finalizing the schedule</li>
</ul>

<h3 id="session-3-position-papers">Session 3: Position papers</h3>

<p>Replication, Communication, and the Population Dynamics of Scientific Discovery.
McElreath, R., &amp; Smaldino, P. E. (2015).</p>

<p>Machine behaviour.
Rahwan, I., Cebrian, M., Obradovich, N., Bongard, J., Bonnefon, J., &amp; Breazeal, C., et al. (2019).</p>

<p>Beyond subjective and objective in statistics (with discussion and rejoinder).
Journal of the Royal Statistical Society A 180, 967–1033. Andrew Gelman and Christian Hennig (2017).</p>

<h3 id="session-4-hypothesis-testing-and-significance">Session 4: Hypothesis testing and significance</h3>

<p>Abandon statistical significance.
American Statistician 73(S1):235–245. Blakeley B. McShane, David Gal, Andrew Gelman, Christian Robert, and Jennifer L. Tackett, 2019.</p>

<p>The ASA Statement on p-Values: Context, Process, and Purpose.
Ronald L. Wasserstein &amp; Nicole A. Lazar. Pages 129-133
https://doi.org/10.1080/00031305.2016.1154108</p>

<p>Bayesian statistics
Jorge López Puga, Martin Krzywinski &amp; Naomi Altman
Nature Methods 12:377–378, 2015.</p>

<p>Jaynes, E. T., 1976. `Confidence Intervals vs Bayesian Intervals,’ in Foundations of Probability Theory, Statistical Inference, and Statistical Theories of Science, W. L. Harper and C. A. Hooker (eds.), D. Reidel, Dordrecht, p. 175;
https://bayes.wustl.edu/etj/articles/confidence.pdf</p>

<h3 id="session-5-prior-information">Session 5: Prior information</h3>

<p>The prior can often only be understood in the context of the likelihood.
Entropy 19:555, 2017. Andrew Gelman, Daniel Simpson, and Michael Betancourt.</p>

<p>The experiment is just as important as the likelihood in understanding the prior: A cautionary note on robust cognitive modelling. Computational Brain and Behavior. Lauren Kennedy, Daniel Simpson, and Andrew Gelman, 2019.</p>

<p>Sparsity information and regularization in the horseshoe and other shrinkage priors. In Electronic Journal of Statistics, 11(2):5018-5051. Juho Piironen and Aki Vehtari (2017). arXiv:1707.01694. After the article was published, the regularized horseshoe prior has been implemented in rstanarm and brms (without conditioning on sigma).</p>

<h3 id="session-6-visualization">Session 6: Visualization</h3>

<p>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction.
Leland McInnes, John Healy, James Melville (2018)</p>

<p>Probabilistic principal component analysis.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 61(3), 611–622.
Tipping, M. E., &amp; Bishop, C. M. (1999).</p>

<p>Bayesian Unidimensional Scaling for visualizing uncertainty in high dimensional datasets with latent ordering of observations.
BMC Bioinformatics, August, 2017.
Lan Huong Nguyen and Susan Holmes (2017)</p>

<h3 id="session-7-feature-selection">Session 7: Feature selection</h3>

<p>XGBoost: A Scalable Tree Boosting System.
In 22nd SIGKDD Conference on Knowledge Discovery and Data Mining, 2016.
Tianqi Chen and Carlos Guestrin.
https://arxiv.org/abs/1603.02754</p>

<p>Projective inference in high-dimensional problems: prediction and feature selection.
Juho Piironen, Markus Paasiniemi, and Aki Vehtari (2018).
arXiv:1810.02406.</p>

<p>Bayesian inference for spatio-temporal spike and slab priors.
In Journal of Machine Learning Research, 18(139):1-58.
Michael Riis Andersen, Aki Vehtari, Ole Winther and Lars Kai Hansen (2017).
arXiv:1509.04752.</p>

<h3 id="session-8-model-selection">Session 8: Model selection</h3>

<p>Bayesian model selection for complex dynamic systems
Christoph Mark, Claus Metzner, Lena Lautscham, Pamela L. Strissel, Reiner Strick, Ben Fabry.
Nature Communications volume 9(1803), 2018</p>

<p>Aki Vehtari, Andrew Gelman and Jonah Gabry (2017).
Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC.
In Statistics and Computing, 27(5):1413–1432.
doi:10.1007/s11222-016-9696-4.
arXiv:1507.04544.</p>

<p>Comparison of Bayesian predictive methods for model selection.
Statistics and Computing, 27(3):711-735. doi:10.1007/s11222-016-9649-y.
Juho Piironen and Aki Vehtari (2017).
arXiv:1503.08650.</p>

<h3 id="session-9-scalable-inference">Session 9: Scalable inference</h3>

<p>Automatic variational inference in Stan. Neural Information Processing Systems. Alp Kucukelbir, Rajesh Ranganath, Andrew Gelman, and David Blei. 2015</p>

<p>Fundamentals and recent developments in approximate Bayesian computation.
Systematic Biology. 66(1),e66-e82 .doi: 10.1093/sysbio/syw077
Lintusaari, Jarno; Gutmann, Michael U.; Dutta, Ritabrata; Kaski, Samuel, Corander, Jukka (2017).</p>

<p>Bayesian Computing with INLA: A Review.
Håvard Rue, Andrea Riebler, Sigrunn H. Sørbye, Janine B. Illian, Daniel P. Simpson, Finn K. Lindgren.
https://arxiv.org/abs/1604.00860</p>

<p>Expectation propagation as a way of life: A framework for Bayesian inference on partitioned data. Journal of Machine Learning Research. 21, 1–53.
Aki Vehtari, Andrew Gelman, Tuomas Sivula, Pasi Jylanki, Dustin Tran, Swupnil Sahai, Paul Blomstedt, John P. Cunningham, David Schiminovich, and Christian P. Robert, 2020</p>

<p>A Conceptual Introduction to Hamiltonian Monte Carlo.
Michael Betancourt.
arXiv:1701.02434</p>

<h3 id="session-10-time-series-and-survival-analysis">Session 10: Time series and survival analysis</h3>

<p>LonGP: an additive Gaussian process regression model for longitudinal study designs.
Nature Communications, 10:1798. 
Lu Cheng, Siddharth Ramchandran, Tommi Vatanen, Niina Lietzen, Riitta Lahesmaa, Aki Vehtari, and Harri Lähdesmäki (2019).</p>

<p>An interpretable probabilistic machine learning method for heterogeneous longitudinal studies.
Juho Timonen, Henrik Mannerström, Aki Vehtari, Harri Lähdesmäki (2019).
arXiv:1912.03549. .</p>

<p>Bayesian Survival Analysis Using the rstanarm R Package.
Samuel L. Brilleman, Eren M. Elci, Jacqueline Buros Novik, Rory Wolfe</p>

<p>Probabilistic Solutions To Ordinary Differential Equations As Non-Linear Bayesian Filtering: A New Perspective.
Filip Tronarp, Hans Kersting, Simo Särkkä, Philipp Hennig (2019).
Statistics and Computing.</p>

<p>A hierarchical Ornstein-Uhlenbeck model for stochastic time series analysis.
Ville Laitinen and Leo Lahti.
Advances in Intelligent Data Analysis XVII. Lecture Notes in Computer Science 11191., Springer, India, 2018. Conference proceedings. https://openresearchlabs.github.io/publications/papers/2018-Laitinen-IDA.pdf</p>

<h3 id="session-11-gaussian-processes">Session 11: Gaussian processes</h3>

<p>Additive multivariate Gaussian processes for joint species distribution modeling with heterogeneous data.
J Vanhatalo, M Hartmann, L Veneranta.
Bayesian Analysis</p>

<p>Boettiger C, Mangel M, Munch S.
Avoiding tipping points in fisheries management through Gaussian process dynamic programming.
Proc Biol Sci. 2015;282(1801):20141631. doi:10.1098/rspb.2014.1631</p>

<p>Gaussian process modeling in approximate Bayesian computation to estimate horizontal gene transfer in bacteria.
Marko Järvenpää, Michael Gutmann, Aki Vehtari and Pekka Marttinen (2018).
The Annals of Applied Statistics, 12(4):2228-2251.
arXiv:1610.06462.</p>

<p>Deep Gaussian Processes.
Andreas C. Damianou, Neil D. Lawrence.
https://arxiv.org/abs/1211.0358</p>

<h3 id="session-12-bayesian-workflow">Session 12: Bayesian workflow</h3>

<p>Visualization in Bayesian workflow.
Journal of the Royal Statistical Society Series A, 182(2):389-402.
Jonah Gabry, Daniel Simpson, Aki Vehtari, Michael Betancourt, and Andrew Gelman (2019).
arXiv:1709.01449.</p>

<p>Toward a principled Bayesian workflow in cognitive science.
Daniel J. Schad, Michael Betancourt, Shravan Vasishth.
https://arxiv.org/abs/1904.12765</p>

<p>Validating  Bayesian  Inference Algorithms with Simulation-Based Calibration.
Sean Talts, Michael Betancourt, Daniel Simpson, Aki Vehtari, Andrew Gelman.
https://arxiv.org/pdf/1804.06788.pdf</p>

<p>Jarno Lintusaari, Henri Vuollekoski, Antti Kangasrääsiö, Kusti Skytén, Marko Järvenpää, Michael Gutmann, Aki Vehtari, Jukka Corander, and Samuel Kaski (2018).
ELFI: Engine for Likelihood Free Inference.
In Journal of Machine Learning Research, 19(16):1-7, 2018.
arXiv:1708.00707</p>

<h3 id="session-13-deep-learning-neural-nets-and-autoencoders">Session 13: Deep learning, neural nets, and autoencoders</h3>

<p>Learning representations of microbe–metabolite interactions.
JT Morton, AA Aksenov, LF Nothias, JR Foulds, RA Quinn, MH Badri, 
Nature methods 16 (12), 1306-1314</p>

<p>An Introduction to Variational Autoencoders.
Diederik P. Kingma, Max Welling.
https://arxiv.org/abs/1906.02691</p>

<p>Bayesian GAN.
Yunus Saatchi, Andrew Gordon Wilson.
https://arxiv.org/abs/1705.09558</p>

<p>Deep Learning: A Bayesian Perspective. Nicholas Polson, Vadim Sokolov.
https://arxiv.org/abs/1706.00473</p>

<p>Towards Bayesian Deep Learning: A Survey.
Hao Wang, Dit-Yan Yeung.
https://arxiv.org/abs/1604.01662</p>

<h3 id="session-14-applications">Session 14: Applications</h3>

<p>Multidomain analyses of a longitudinal human microbiome intestinal cleanout perturbation experiment.
Julia Fukuyama, Laurie Rumker, Kris Sankaran, Pratheepa Jeganathan, Les Dethlefsen, David A. Relman, Susan P. Holmes (2017)
PLOS Computational Biology, August 2017.</p>

<p>Fast hierarchical Bayesian analysis of population structure.
Tonkin-Hill, Gerry; Lees, John A; Bentley, Stephen D; Frost, Simon DW &amp; Corander, Jukka (2019).
Nucleic Acids Research. 47(11),5539-5549.
doi: 10.1093/nar/gkz361</p>

<p>Additive multivariate Gaussian processes for joint species distribution modeling with heterogeneous data.
Jarno Vanhatalo†, Marcelo Hartmann‡and Lari Veneranta.
Bayesian analysis 2019.
https://arxiv.org/pdf/1809.02432.pdf</p>

<h3 id="session-15-wrap-up">Session 15: Wrap-up</h3>

<h2 id="other-sources">Other sources</h2>

<p>You can also consider topics from the following books:</p>

<ul>
  <li><a href="https://xcelab.net/rm/statistical-rethinking/">Statistical rethinking</a> (Richard McElreath; CRC Press)</li>
  <li><a href="http://www.stat.columbia.edu/~gelman/book/">Bayesian Data Analysis</a> (Gelman et al. Chapman &amp; Hall / CRC)</li>
  <li><a href="https://www.springer.com/gp/book/9780387310732">Pattern recognition and Machine Learning</a> (Bishop; Springer)</li>
  <li><a href="https://www.springer.com/gp/book/9780387848570">The Elements of Statistical Learning</a> (Hastie et al; Springer)</li>
  <li><a href="https://www.amazon.com/Networks-Crowds-Markets-Reasoning-Connected/dp/0521195330">Networks, Crowds, and Markets</a> (Easley &amp; Kleinberg; Cambridge University Press)</li>
</ul>


  </article>

</div>

	
      </div>
    </div>

    <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">
	  <div class="row">
		<div class="col-sm-4">
			
		  <p>&copy 2018-2019 Leo Lahti<br/ >
		      Turku Data Science Group<br/ >
		      Site: Jekyll <a href="/aboutwebsite.html">open source</a></p>.
              <!--<p>We are part of <a href="http://www.utu.fi/">University of Turku</a></p>-->
		   <p>  </p><p>

		</div>
		
		<div class="col-sm-4">
		  Contact:<br />
		  FI-20014 University of Turku<br />
		  Finland 
            (<a href="http://www.utu.fi/en/university/contact/Pages/home.aspx">Directions</a>)
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="/js/bootstrap.min.js"></script>


  </body>

  <p></p>
  
</html>

